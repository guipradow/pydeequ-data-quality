{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['SPARK_VERSION'] = os.getenv('SPARK_VERSION')\n",
    "os.environ['PYSPARK_PYTHON'] = os.getenv('PYSPARK_PYTHON')\n",
    "os.environ['SPARK_HOME'] = os.getenv('SPARK_HOME')\n",
    "os.environ['HADOOP_HOME'] = os.getenv('HADOOP_HOME')\n",
    "os.environ['JAVA_HOME'] = os.getenv('JAVA_HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pydeequ\n",
    "from pydeequ.analyzers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config('spark.ui.port', '4050')\n",
    "    .config('spark.jars.packages', pydeequ.deequ_maven_coord)\n",
    "    .config('spark.jars.excludes', pydeequ.f2j_maven_coord)\n",
    "    .appName('SparkSQL')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL da Spark UI: http://DESKTOP-E8QPPRO:4050\n"
     ]
    }
   ],
   "source": [
    "ui_url = spark.sparkContext.uiWebUrl\n",
    "print(\"URL da Spark UI:\", ui_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_remetente_destinatario = StructType([\n",
    "    StructField('nome', StringType()),\n",
    "    StructField('banco', StringType()),\n",
    "    StructField('tipo', StringType()),\n",
    "])\n",
    "\n",
    "\n",
    "schema_base_pix = StructType([\n",
    "    StructField('id_transacao', IntegerType()),\n",
    "    StructField('valor', DoubleType()),\n",
    "    StructField('remetente', schema_remetente_destinatario),\n",
    "    StructField('destinatario', schema_remetente_destinatario),\n",
    "    StructField('transaction_date', TimestampType()),\n",
    "    StructField('chave_pix', StringType()),\n",
    "    StructField('categoria', StringType()),\n",
    "    StructField('fraude', IntegerType())\n",
    "])\n",
    "\n",
    "PATH_JSON = './data/case_final.json'\n",
    "\n",
    "df = spark.read.json(\n",
    "    PATH_JSON,\n",
    "    schema=schema_base_pix,\n",
    "    timestampFormat='yyyy-MM-dd HH:mm:ss'\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    'destinatario_nome', col('destinatario').getField('nome')\n",
    ").withColumn(\n",
    "    'destinatario_banco', col('destinatario').getField('banco')\n",
    ").withColumn(\n",
    "    'destinatario_tipo', col('destinatario').getField('tipo')\n",
    ").withColumn(\n",
    "    'remetente_nome', col('remetente').getField('nome')\n",
    ").withColumn(\n",
    "    'remetente_banco', col('remetente').getField('banco')\n",
    ").withColumn(\n",
    "    'remetente_tipo', col('remetente').getField('tipo')\n",
    ").drop('remetente', 'destinatario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-------------------+---------+-------------+------+--------------------+------------------+-----------------+------------------+---------------+--------------+\n",
      "|id_transacao|             valor|   transaction_date|chave_pix|    categoria|fraude|   destinatario_nome|destinatario_banco|destinatario_tipo|    remetente_nome|remetente_banco|remetente_tipo|\n",
      "+------------+------------------+-------------------+---------+-------------+------+--------------------+------------------+-----------------+------------------+---------------+--------------+\n",
      "|        1000|            588.08|2021-07-16 05:00:55|aleatoria|       outros|     0|         Calebe Melo|             Caixa|               PF|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1001|           80682.5|2022-04-20 12:34:01|  celular|transferencia|     1|  Davi Lucas Pereira|             Caixa|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1002|             549.9|2022-07-10 16:51:34|      cpf|        lazer|     0|      Sabrina Castro|            Nubank|               PF|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1003|             90.83|2022-10-20 10:57:36|aleatoria|   transporte|     0|Francisco da Conc...|            Nubank|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1004|13272.619999999999|2021-04-06 20:26:51|    email|transferencia|     0|   Isabelly Ferreira|               BTG|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1005|           9347.58|2022-07-24 15:22:27|aleatoria|        saude|     0|Srta. Maria da Cunha|              Itau|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1006|           7836.76|2022-10-05 19:20:24|      cpf|    presentes|     0|     Catarina Duarte|                C6|               PF|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1007|           3883.62|2021-04-24 17:36:34|      cpf|    vestuario|     0|       Vitor Correia|                XP|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1008|               4.0|2021-11-16 21:46:47|aleatoria|        saude|     0|         Theo Novaes|                C6|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1009|              24.3|2021-07-26 02:08:49|      cpf|transferencia|     0|     Isabel Caldeira|                XP|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1010|           87555.3|2022-03-14 15:34:45|aleatoria|transferencia|     1|Sr. Henrique Cardoso|            Nubank|               PF|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1011|          21345.91|2021-10-31 04:31:51|      cpf|transferencia|     1|   Felipe Cavalcanti|            Nubank|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1012|          73605.85|2021-04-30 19:19:56|  celular|transferencia|     1|     Dr. Davi da Luz|          Bradesco|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1013|             93.53|2023-01-13 13:39:57|      cpf|  alimentacao|     0|    Stephany Cardoso|                C6|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1014|            564.11|2022-05-27 23:06:08|aleatoria|    vestuario|     0|   Sra. Julia Araujo|              Itau|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1015|              3.59|2021-10-06 21:19:58|    email|        saude|     0|     Carolina Farias|            Nubank|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1016|          19164.89|2022-03-06 17:59:43|    email|  alimentacao|     0|   Isabelly da Costa|            Nubank|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1017|             68.45|2022-04-01 18:17:40|aleatoria|    vestuario|     0|Joao Miguel Silveira|                C6|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1018|            941.25|2022-05-23 00:28:13|  celular|    vestuario|     0|       Matheus Moura|                C6|               PF|Jonathan Gonsalves|            BTG|            PF|\n",
      "|        1019|27009.910000000003|2021-08-04 23:22:37|    email|transferencia|     1| Gabrielly Goncalves|              Itau|               PJ|Jonathan Gonsalves|            BTG|            PF|\n",
      "+------------+------------------+-------------------+---------+-------------+------+--------------------+------------------+-----------------+------------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysisResult = (\n",
    "    AnalysisRunner(spark).onData(df)\n",
    "    .addAnalyzer(Size())\n",
    "    .addAnalyzer(Completeness('id_transacao'))\n",
    "    .addAnalyzer(Compliance('valor', 'valor > 0'))\n",
    "    .run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------+--------+\n",
      "| entity|    instance|        name|   value|\n",
      "+-------+------------+------------+--------+\n",
      "|Dataset|           *|        Size|100000.0|\n",
      "| Column|id_transacao|Completeness|     1.0|\n",
      "| Column|       valor|  Compliance| 0.99972|\n",
      "+-------+------------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysisResult_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeequ.suggestions import ConstraintSuggestionRunner, DEFAULT\n",
    "\n",
    "suggestionResult = ConstraintSuggestionRunner(spark).onData(df).addConstraintRule(DEFAULT()).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sugestão de constraint: \"destinatario_nome\": 'destinatario_nome' is not null\n",
      "PySpark Code: .isComplete(\"destinatario_nome\")\n",
      "\n",
      "Sugestão de constraint: \"remetente_nome\": 'remetente_nome' has value range 'Jonathan Gonsalves'\n",
      "PySpark Code: .isContainedIn(\"remetente_nome\", [\"Jonathan Gonsalves\"])\n",
      "\n",
      "Sugestão de constraint: \"remetente_nome\": 'remetente_nome' is not null\n",
      "PySpark Code: .isComplete(\"remetente_nome\")\n",
      "\n",
      "Sugestão de constraint: \"id_transacao\": 'id_transacao' is not null\n",
      "PySpark Code: .isComplete(\"id_transacao\")\n",
      "\n",
      "Sugestão de constraint: \"id_transacao\": 'id_transacao' has no negative values\n",
      "PySpark Code: .isNonNegative(\"id_transacao\")\n",
      "\n",
      "Sugestão de constraint: \"id_transacao\": 'id_transacao' is unique\n",
      "PySpark Code: .isUnique(\"id_transacao\")\n",
      "\n",
      "Sugestão de constraint: \"remetente_banco\": 'remetente_banco' has value range 'BTG'\n",
      "PySpark Code: .isContainedIn(\"remetente_banco\", [\"BTG\"])\n",
      "\n",
      "Sugestão de constraint: \"remetente_banco\": 'remetente_banco' is not null\n",
      "PySpark Code: .isComplete(\"remetente_banco\")\n",
      "\n",
      "Sugestão de constraint: \"categoria\": 'categoria' has value range 'transferencia', 'alimentacao', 'vestuario', 'saude', 'lazer', 'educacao', 'outros', 'presentes', 'transporte'\n",
      "PySpark Code: .isContainedIn(\"categoria\", [\"transferencia\", \"alimentacao\", \"vestuario\", \"saude\", \"lazer\", \"educacao\", \"outros\", \"presentes\", \"transporte\"])\n",
      "\n",
      "Sugestão de constraint: \"categoria\": 'categoria' is not null\n",
      "PySpark Code: .isComplete(\"categoria\")\n",
      "\n",
      "Sugestão de constraint: \"categoria\": 'categoria' has value range 'transferencia', 'alimentacao', 'vestuario', 'saude', 'lazer', 'educacao', 'outros', 'presentes' for at least 90.0% of values\n",
      "PySpark Code: .isContainedIn(\"categoria\", [\"transferencia\", \"alimentacao\", \"vestuario\", \"saude\", \"lazer\", \"educacao\", \"outros\", \"presentes\"], lambda x: x >= 0.9, \"It should be above 0.9!\")\n",
      "\n",
      "Sugestão de constraint: \"remetente_tipo\": 'remetente_tipo' has value range 'PF'\n",
      "PySpark Code: .isContainedIn(\"remetente_tipo\", [\"PF\"])\n",
      "\n",
      "Sugestão de constraint: \"remetente_tipo\": 'remetente_tipo' is not null\n",
      "PySpark Code: .isComplete(\"remetente_tipo\")\n",
      "\n",
      "Sugestão de constraint: \"chave_pix\": 'chave_pix' has value range 'email', 'cpf', 'celular', 'aleatoria'\n",
      "PySpark Code: .isContainedIn(\"chave_pix\", [\"email\", \"cpf\", \"celular\", \"aleatoria\"])\n",
      "\n",
      "Sugestão de constraint: \"chave_pix\": 'chave_pix' is not null\n",
      "PySpark Code: .isComplete(\"chave_pix\")\n",
      "\n",
      "Sugestão de constraint: \"fraude\": 'fraude' has value range '0', '1'\n",
      "PySpark Code: .isContainedIn(\"fraude\", [\"0\", \"1\"])\n",
      "\n",
      "Sugestão de constraint: \"fraude\": 'fraude' is not null\n",
      "PySpark Code: .isComplete(\"fraude\")\n",
      "\n",
      "Sugestão de constraint: \"fraude\": 'fraude' has no negative values\n",
      "PySpark Code: .isNonNegative(\"fraude\")\n",
      "\n",
      "Sugestão de constraint: \"destinatario_tipo\": 'destinatario_tipo' has value range 'PJ', 'PF'\n",
      "PySpark Code: .isContainedIn(\"destinatario_tipo\", [\"PJ\", \"PF\"])\n",
      "\n",
      "Sugestão de constraint: \"destinatario_tipo\": 'destinatario_tipo' is not null\n",
      "PySpark Code: .isComplete(\"destinatario_tipo\")\n",
      "\n",
      "Sugestão de constraint: \"valor\": 'valor' is not null\n",
      "PySpark Code: .isComplete(\"valor\")\n",
      "\n",
      "Sugestão de constraint: \"valor\": 'valor' has no negative values\n",
      "PySpark Code: .isNonNegative(\"valor\")\n",
      "\n",
      "Sugestão de constraint: \"transaction_date\": 'transaction_date' is not null\n",
      "PySpark Code: .isComplete(\"transaction_date\")\n",
      "\n",
      "Sugestão de constraint: \"transaction_date\": 'transaction_date' is unique\n",
      "PySpark Code: .isUnique(\"transaction_date\")\n",
      "\n",
      "Sugestão de constraint: \"destinatario_banco\": 'destinatario_banco' has value range 'XP', 'BTG', 'Nubank', 'Itau', 'Caixa', 'C6', 'Bradesco'\n",
      "PySpark Code: .isContainedIn(\"destinatario_banco\", [\"XP\", \"BTG\", \"Nubank\", \"Itau\", \"Caixa\", \"C6\", \"Bradesco\"])\n",
      "\n",
      "Sugestão de constraint: \"destinatario_banco\": 'destinatario_banco' is not null\n",
      "PySpark Code: .isComplete(\"destinatario_banco\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sugg in suggestionResult['constraint_suggestions']:\n",
    "    print(f'Sugestão de constraint: \\\"{sugg[\"column_name\"]}\\\": {sugg[\"description\"]}')\n",
    "    print(f'PySpark Code: {sugg[\"code_for_constraint\"]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeequ.checks import Check, CheckLevel, ConstrainableDataTypes\n",
    "from pydeequ.verification import VerificationResult, VerificationSuite\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, 'Review CHeck')\n",
    "error = Check(spark, CheckLevel.Error, 'Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkResult = (\n",
    "    VerificationSuite(spark)\n",
    "    .onData(df)\n",
    "    .addCheck(\n",
    "        check.hasDataType('id_transacao', ConstrainableDataTypes.Integral)\n",
    "        .isNonNegative('id_transacao')\n",
    "        .isComplete('id_transacao')\n",
    "    ).run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
      "|check       |check_level|check_status|constraint                                                                                                                  |constraint_status|constraint_message|\n",
      "+------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
      "|Review CHeck|Warning    |Success     |AnalysisBasedConstraint(DataType(id_transacao,None),<function1>,Some(<function1>),None)                                     |Success          |                  |\n",
      "|Review CHeck|Warning    |Success     |ComplianceConstraint(Compliance(id_transacao is non-negative,COALESCE(CAST(id_transacao AS DECIMAL(20,10)), 0.0) >= 0,None))|Success          |                  |\n",
      "|Review CHeck|Warning    |Success     |CompletenessConstraint(Completeness(id_transacao,None))                                                                     |Success          |                  |\n",
      "+------------+-----------+------------+----------------------------------------------------------------------------------------------------------------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "checkResult_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkResult = (\n",
    "    VerificationSuite(spark)\n",
    "    .onData(df)\n",
    "    .addCheck(\n",
    "        error.isContainedIn('remetente_tipo', ['CNPJ'])\n",
    "    ).run()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+------------+--------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n",
      "|check|check_level|check_status|constraint                                                                                                                      |constraint_status|constraint_message                                  |\n",
      "+-----+-----------+------------+--------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n",
      "|Error|Error      |Error       |ComplianceConstraint(Compliance(remetente_tipo contained in CNPJ,`remetente_tipo` IS NULL OR `remetente_tipo` IN ('CNPJ'),None))|Failure          |Value: 0.0 does not meet the constraint requirement!|\n",
      "+-----+-----------+------------+--------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "checkResult_df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
